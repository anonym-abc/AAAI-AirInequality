{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rapidfuzz import process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using census data which is used earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"AirQuality/RQ3/Dataset/IntermediateData_144Cities/india-districts-population-census-2011.csv\")\n",
    "city_state_df = pd.read_csv(\"AirQuality/Dataset/Ground_Truth_2023_Final.csv\")\n",
    "city_state_df = city_state_df[[\"city\",\"state\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['District code', 'State name', 'District name', 'Population', 'Male',\n",
       "       'Female', 'Literate', 'Male_Literate', 'Female_Literate', 'SC',\n",
       "       ...\n",
       "       'Power_Parity_Rs_90000_150000', 'Power_Parity_Rs_45000_150000',\n",
       "       'Power_Parity_Rs_150000_240000', 'Power_Parity_Rs_240000_330000',\n",
       "       'Power_Parity_Rs_150000_330000', 'Power_Parity_Rs_330000_425000',\n",
       "       'Power_Parity_Rs_425000_545000', 'Power_Parity_Rs_330000_545000',\n",
       "       'Power_Parity_Above_Rs_545000', 'Total_Power_Parity'],\n",
       "      dtype='object', length=118)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\n",
    "    'District name': 'city',\n",
    "    'State name': 'state'\n",
    "})\n",
    "df['city'] = df['city'].str.strip().str.lower()\n",
    "df['state'] = df['state'].str.strip().str.lower()\n",
    "city_state_df['city'] = city_state_df['city'].str.strip().str.lower()\n",
    "city_state_df['state'] = city_state_df['state'].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = city_state_df.merge(\n",
    "    df[['city', 'state', 'Population']],\n",
    "    on=['city', 'state'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(89)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['Population'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['city', 'state', 'Population'], dtype='object')\n",
      "(201, 3)\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.columns)\n",
    "print(merged_df.shape)\n",
    "merged_df.to_csv(\"Population.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using census data including town"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['State', 'District', 'Subdistt', 'Town/Village', 'Ward', 'EB', 'Level',\n",
       "       'Name', 'TRU', 'No_HH', 'TOT_P', 'TOT_M', 'TOT_F', 'P_06', 'M_06',\n",
       "       'F_06', 'P_SC', 'M_SC', 'F_SC', 'P_ST', 'M_ST', 'F_ST', 'P_LIT',\n",
       "       'M_LIT', 'F_LIT', 'P_ILL', 'M_ILL', 'F_ILL', 'TOT_WORK_P', 'TOT_WORK_M',\n",
       "       'TOT_WORK_F', 'MAINWORK_P', 'MAINWORK_M', 'MAINWORK_F', 'MAIN_CL_P',\n",
       "       'MAIN_CL_M', 'MAIN_CL_F', 'MAIN_AL_P', 'MAIN_AL_M', 'MAIN_AL_F',\n",
       "       'MAIN_HH_P', 'MAIN_HH_M', 'MAIN_HH_F', 'MAIN_OT_P', 'MAIN_OT_M',\n",
       "       'MAIN_OT_F', 'MARGWORK_P', 'MARGWORK_M', 'MARGWORK_F', 'MARG_CL_P',\n",
       "       'MARG_CL_M', 'MARG_CL_F', 'MARG_AL_P', 'MARG_AL_M', 'MARG_AL_F',\n",
       "       'MARG_HH_P', 'MARG_HH_M', 'MARG_HH_F', 'MARG_OT_P', 'MARG_OT_M',\n",
       "       'MARG_OT_F', 'MARGWORK_3_6_P', 'MARGWORK_3_6_M', 'MARGWORK_3_6_F',\n",
       "       'MARG_CL_3_6_P', 'MARG_CL_3_6_M', 'MARG_CL_3_6_F', 'MARG_AL_3_6_P',\n",
       "       'MARG_AL_3_6_M', 'MARG_AL_3_6_F', 'MARG_HH_3_6_P', 'MARG_HH_3_6_M',\n",
       "       'MARG_HH_3_6_F', 'MARG_OT_3_6_P', 'MARG_OT_3_6_M', 'MARG_OT_3_6_F',\n",
       "       'MARGWORK_0_3_P', 'MARGWORK_0_3_M', 'MARGWORK_0_3_F', 'MARG_CL_0_3_P',\n",
       "       'MARG_CL_0_3_M', 'MARG_CL_0_3_F', 'MARG_AL_0_3_P', 'MARG_AL_0_3_M',\n",
       "       'MARG_AL_0_3_F', 'MARG_HH_0_3_P', 'MARG_HH_0_3_M', 'MARG_HH_0_3_F',\n",
       "       'MARG_OT_0_3_P', 'MARG_OT_0_3_M', 'MARG_OT_0_3_F', 'NON_WORK_P',\n",
       "       'NON_WORK_M', 'NON_WORK_F'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_state_df = pd.read_csv(\"AirQuality/Dataset/Ground_Truth_2023_Final.csv\")\n",
    "city_state_df = city_state_df[[\"city\",\"state\"]].drop_duplicates()\n",
    "\n",
    "population_df = pd.read_excel(\"AirQuality/RQ3/Dataset/IntermediateData_144Cities/2011-IndiaStateDistSbDistTwn.xlsx\")\n",
    "population_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_state_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_df = population_df[population_df['TRU'] == 'Total'].copy()\n",
    "\n",
    "def normalize(x):\n",
    "    return str(x).strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_state_df['city'] = city_state_df['city'].apply(normalize)\n",
    "city_state_df['state'] = city_state_df['state'].apply(normalize)\n",
    "population_df['Name'] = population_df['Name'].apply(normalize)\n",
    "population_df['Level'] = population_df['Level'].astype(str).apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_df = population_df[population_df['Level'] == 'state']\n",
    "district_df = population_df[population_df['Level'] == 'district']\n",
    "subdist_df = population_df[population_df['Level'] == 'sub-district']\n",
    "town_df = population_df[population_df['Level'] == 'town']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_name_corrections = {\n",
    "    'delhi': 'nct of delhi',\n",
    "    'jammu and kashmir': 'jammu & kashmir'\n",
    "}\n",
    "\n",
    "city_state_df['state_corrected'] = city_state_df['state'].replace(state_name_corrections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_to_code = dict(zip(state_df['Name'], state_df['State']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_rows = []\n",
    "\n",
    "for _, row in city_state_df.iterrows():\n",
    "    city = row['city']\n",
    "    state = row['state_corrected']\n",
    "\n",
    "    state_code = state_to_code.get(state)\n",
    "    if state_code is None:\n",
    "        matched_rows.append({\n",
    "            'city': city,\n",
    "            'state': state,\n",
    "            'matched_city': None,\n",
    "            'level': None,\n",
    "            'population': None,\n",
    "            'score': None\n",
    "        })\n",
    "        continue\n",
    "\n",
    "\n",
    "    found = False\n",
    "    for level_name, level_df in [\n",
    "        (\"district\", district_df),\n",
    "        (\"sub-district\", subdist_df),\n",
    "        (\"town\", town_df)\n",
    "    ]:\n",
    "        candidates = level_df[level_df['State'] == state_code]\n",
    "        if candidates.empty:\n",
    "            continue\n",
    "\n",
    "        match, score, _ = process.extractOne(city, candidates['Name'])\n",
    "        if score >= 85:  # Adjust if needed\n",
    "            matched_row = candidates[candidates['Name'] == match].iloc[0]\n",
    "            matched_rows.append({\n",
    "                'city': city,\n",
    "                'state': state,\n",
    "                'matched_name': match,\n",
    "                'population': matched_row['TOT_P'],\n",
    "                'level': level_name,\n",
    "                'score': score\n",
    "            })\n",
    "            found = True\n",
    "            break\n",
    "\n",
    "    if not found:\n",
    "        matched_rows.append({\n",
    "            'city': city,\n",
    "            'state': state,\n",
    "            'matched_name': None,\n",
    "            'population': None,\n",
    "            'level': None,\n",
    "            'score': None\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cities: 201\n",
      "Matched: 163\n",
      "Unmatched: 38\n"
     ]
    }
   ],
   "source": [
    "final_df = pd.DataFrame(matched_rows, columns=[\n",
    "    'city', 'state', 'matched_city', 'level', 'population', 'score'\n",
    "])\n",
    "\n",
    "print(\"Total cities:\", len(final_df))\n",
    "print(\"Matched:\", final_df['population'].notna().sum())\n",
    "print(\"Unmatched:\", final_df['population'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"Population.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diya_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
